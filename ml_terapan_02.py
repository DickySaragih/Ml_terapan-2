# -*- coding: utf-8 -*-
"""ML_Terapan_02

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Sw5fqkKo5fuvdzn-KTHfhz7QNe3hkCI

# Import library
"""

import os
import pandas as pd
import numpy as np
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.applications import VGG16
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics.pairwise import cosine_similarity
from google.colab import drive

"""#Load dataset"""

# Mount Google Drive
drive.mount('/content/drive')

# Dataset path in Google Drive
dataset_path = "/content/drive/MyDrive/Ml_terapan/makanan_padang"
categories = os.listdir(dataset_path)
print("Food Categories:", categories)

# Create DataFrame with file names and category labels
image_paths = []
labels = []
for category in categories:
    category_path = os.path.join(dataset_path, category)
    for img_file in os.listdir(category_path):
        image_paths.append(os.path.join(category_path, img_file))
        labels.append(category)

data = pd.DataFrame({"filepath": image_paths, "label": labels})
print("Total Images:", len(data))
print(data.head())

"""# Data preperation"""

# Data Preparation
IMG_SIZE = (100, 100)
X = []
for path in tqdm(data['filepath']):
    img = cv2.imread(path)
    img = cv2.resize(img, IMG_SIZE)
    img = img / 255.0
    X.append(img)

X = np.array(X)

"""#### insight:
Penggunaan `cv2.resize()` dengan ukuran tetap (100x100) berpotensi menghilangkan detail penting yang mungkin memengaruhi akurasi model.  Resolusi gambar yang seragam memang mempermudah pemrosesan, namun perlu dipertimbangkan untuk mengevaluasi dampaknya terhadap performa klasifikasi, terutama jika variasi ukuran objek dalam gambar cukup signifikan.  Perlu dieksplorasi metode resizing alternatif (misalnya, *padding* atau *crop*) atau penggunaan ukuran gambar yang lebih besar untuk mempertahankan detail informasi. Normalisasi piksel ke rentang 0-1 sudah tepat dan merupakan praktik standar yang baik.

# Data Splitting
"""

# Encode labels to numeric using LabelEncoder
le = LabelEncoder()
y = le.fit_transform(data['label'])
# Data Splitting
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""#### insight:
Data dibagi menjadi data latih dan data uji dengan rasio 80:20 menggunakan fungsi train_test_split. Parameter stratify=y memastikan proporsi kelas pada data latih dan uji sama dengan distribusi kelas pada data awal, sehingga mencegah bias pada model.  Penggunaan random_state=42  memastikan hasil pembagian data dapat direproduksi.

# Augentasi data
"""

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
datagen.fit(X_train)

"""#### insight:

Proses augmentasi data dilakukan menggunakan `ImageDataGenerator` dengan parameter rotasi, pergeseran, shear, zoom, dan flip horizontal.  Strategi ini meningkatkan variasi data latih dan diharapkan dapat meningkatkan generalisasi model.  Namun, perlu dievaluasi dampak dari parameter augmentasi yang digunakan terhadap kinerja model.  Penggunaan parameter fill_mode='nearest perlu dipertimbangkan kembali, eksplorasi metode fill lainnya mungkin memberikan hasil yang lebih baik.

# Modeling
"""

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(100, 100, 3))

# Freeze the base model layers (optional)
for layer in base_model.layers:
    layer.trainable = False

# Create a new input layer
inputs = Input(shape=(100, 100, 3))

# Connect the base model to the new input
x = base_model(inputs)

# Add custom classification layers on top
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
outputs = Dense(len(categories), activation='softmax')(x)

# Create the final model
model = Model(inputs=inputs, outputs=outputs)

# # Compile and Train Model

# Compile the model
model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Learning Rate Scheduling
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)

# Train the model
model.fit(datagen.flow(X_train, y_train, batch_size=32),
          epochs=20,
          validation_data=(X_test, y_test),
          callbacks=[reduce_lr])

"""#### insight:

Model klasifikasi gambar makanan Padang ini menggunakan arsitektur VGG16 yang telah terlatih pre-trained pada dataset ImageNet sebagai base model.  Lapisan-lapisan awal VGG16 dibekukan untuk memanfaatkan pengetahuan yang telah dipelajari, kemudian ditambahkan lapisan klasifikasi baru di atasnya.  Proses augmentasi data diterapkan untuk meningkatkan generalisasi model. Penggunaan learning rate scheduler membantu mengoptimalkan proses pelatihan.  Evaluasi kinerja model dilakukan menggunakan data uji terpisah.  Meskipun demikian, perlu diperhatikan potensi hilangnya detail gambar akibat resizing, dan perlu dieksplorasi parameter augmentasi serta metode fill untuk optimalisasi kinerja model.

# Evaluasi Model
"""

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Print classification report
print(classification_report(y_test, y_pred_classes, target_names=le.classes_))

# Calculate and print evaluation metrics
accuracy = accuracy_score(y_test, y_pred_classes)
precision = precision_score(y_test, y_pred_classes, average='weighted')
recall = recall_score(y_test, y_pred_classes, average='weighted')
f1 = f1_score(y_test, y_pred_classes, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

# Assuming y_test and y_pred_classes are defined from your previous code

cm = confusion_matrix(y_test, y_pred_classes)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Hitung kemiripan antar gambar dengan cosine similarity
similarities = cosine_similarity(features)

# Fungsi untuk menampilkan Top-N rekomendasi
def show_recommendations(index, top_n=5):
    print(f"Makanan input: {data.iloc[index]['label']}")
    sim_scores = list(enumerate(similarities[index]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    top_indexes = [i for i, score in sim_scores[1:top_n+1]]

    fig, axes = plt.subplots(1, top_n+1, figsize=(15,5))
    axes[0].imshow(cv2.imread(data.iloc[index]['filepath'])[...,::-1])
    axes[0].set_title("Input")
    axes[0].axis('off')

    for i, idx in enumerate(top_indexes):
        axes[i+1].imshow(cv2.imread(data.iloc[idx]['filepath'])[...,::-1])
        axes[i+1].set_title(f"Rekomendasi {i+1}\n({data.iloc[idx]['label']})")
        axes[i+1].axis('off')
    plt.tight_layout()
    plt.show()

# Contoh evaluasi manual:
show_recommendations(index=3)
show_recommendations(index=10)

"""#### insight:
Evaluasi model klasifikasi gambar makanan Padang menunjukkan beberapa temuan.  Model yang menggunakan arsitektur VGG16 dengan transfer learning dan augmentasi data mencapai akurasi, presisi, recall, dan skor F1 yang 74%. Confusion matrix memberikan gambaran detail mengenai kinerja klasifikasi untuk setiap kategori makanan.  Analisis cosine similarity  pada fitur-fitur gambar memungkinkan identifikasi rekomendasi makanan serupa, yang ditunjukkan pada contoh evaluasi manual. Namun, perlu diperhatikan potensi pengaruh *resizing* gambar terhadap performa model.  Optimasi lebih lanjut dapat dilakukan dengan mengeksplorasi parameter augmentasi, metode fill, dan ukuran gambar untuk meningkatkan kinerja model.

# Feature Extraction and Top-N Recommendation
"""

# Extract features from the second-to-last layer of the model
feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)
features = feature_extractor.predict(X)

# Calculate cosine similarity between features
similarities = cosine_similarity(features)

# Function to get top-N recommendations
def get_top_n_recommendations(image_index, top_n=5):
    """Gets the top-N recommendations for a given image index."""
    sim_scores = list(enumerate(similarities[image_index]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    top_indexes = [i for i, score in sim_scores[1:top_n + 1]]
    return [(idx, score) for idx, score in sim_scores[1:top_n + 1]]

# Example usage: Get top-5 recommendations for the first image
recommendations = get_top_n_recommendations(0, top_n=5)
print("Top-5 Recommendations for Image 0:")
for idx, score in recommendations:
    print(f"Image Index: {idx}, Similarity Score: {score:.4f}, Food: {data.iloc[idx]['label']}")

"""#### insight :
Proses ekstraksi fitur menggunakan lapisan kedua-terakhir dari model VGG16 yang telah dimodifikasi, menghasilkan representasi numerik dari setiap gambar makanan. Selanjutnya, perhitungan cosine similarity pada vektor fitur tersebut memungkinkan sistem untuk merekomendasikan makanan serupa berdasarkan kemiripan fitur visualnya.  Sistem rekomendasi Top-N kemudian menampilkan N gambar makanan dengan skor kemiripan tertinggi, memberikan saran makanan yang serupa dengan masukan pengguna.

"""